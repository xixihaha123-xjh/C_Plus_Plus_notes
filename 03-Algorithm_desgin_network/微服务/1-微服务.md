转载  [https://www.zhihu.com/search?type=content&q=%E5%BE%AE%E6%9C%8D%E5%8A%A1](https://www.zhihu.com/search?type=content&q=微服务) 

## 1 问题

（1）本文将介绍微服务架构和相关的组件？

（2）介绍他们是什么？

（3）为什么要使用微服务架构和这些组件 ？

## 2 微服务 vs 单体应用

（1）最初的需求（单体应用，即将所有功能都打包成在一个独立单元的应用程序）

1. 从单体应用到微服务并不是一蹴而就的，这是一个逐渐演变的过程，以一个网上超市应用为例来说明这一过程

![单体应用](F:/00-C++后台服务器学习/03-算法与设计与网络/微服务/pic/1-微服务.jpg)

（2）随着业务的发展，竞争的压力下，小明小皮决定开展一些营销手段 ，开展促销活动，拓展渠道，新增移动端营销，精准营销，利用历史数据对用户进行分析，提供个性化服务。 

![单体应用](F:/00-C++后台服务器学习/03-算法与设计与网络/微服务/pic/2-业务发展.jpg)

这一阶段存在很多不合理的地方：

```
1-网站和移动端应用有很多相同业务逻辑的重复代码。
2-数据有时候通过数据库共享，有时候通过接口调用传输。接口调用关系杂乱。
3-单个应用为了给其他应用提供接口，渐渐地越改越大，包含了很多本来就不属于它的逻辑。应用边界模糊，功能归属混乱。
4-管理后台在一开始的设计中保障级别较低。加入数据分析和促销管理相关功能后出现性能瓶颈，影响了其他应用。
5-数据库表结构被多个应用依赖，无法重构和优化。
6-所有应用都在一个数据库上操作，数据库出现性能瓶颈。特别是数据分析跑起来的时候，数据库性能急剧下降。
7-开发、测试、部署、维护愈发困难。即使只改动一个小功能，也需要整个应用一起发布。有时候发布会不小心带上了一些未经测试的代码，或者修改了一个功能后，另一个意想不到的地方出错了。为了减轻发布可能产生的问题的影响和线上业务停顿的影响，所有应用都要在凌晨三四点执行发布。发布后为了验证应用正常运行，还得盯到第二天白天的用户高峰期……
8-团队出现推诿扯皮现象。关于一些公用的功能应该建设在哪个应用上的问题常常要争论很久，最后要么干脆各做各的，或者随便放个地方但是都不维护。
```

尽管有着诸多问题，但也不能否认这一阶段的成果：快速地根据业务变化建设了系统。不过**紧迫且繁重的任务容易使人陷入局部、短浅的思维方式，从而做出妥协式的决策**。在这种架构中，每个人都只关注在自己的一亩三分地，缺乏全局的、长远的设计。长此以往，系统建设将会越来越困难，甚至陷入不断推翻、重建的循环。

（3）改变.....

微服务改造的过程实际上也是个抽象的过程。小明和小红整理了网上超市的业务逻辑，抽象出公用的业务能力，做成几个公共服务：

- 用户服务
- 商品服务
- 促销服务
- 订单服务
- 数据分析服务

各个应用后台只需从这些服务获取所需的数据，从而删去了大量冗余的代码，就剩个轻薄的控制层和前端。这一阶段的架构如下：

![改变](F:/00-C++后台服务器学习/03-算法与设计与网络/微服务/pic/3-改变.jpg)



这个阶段只是将服务分开了，数据库依然是共用的，所以一些烟囱式系统的缺点仍然存在：

1 - 数据库成为性能瓶颈，并且有单点故障的风险。

2 - 数据管理趋向混乱。即使一开始有良好的模块化设计，随着时间推移，总会有一个服务直接从数据库取另一个服务的数据的现象。

3 - 数据库表结构可能被多个服务依赖，牵一发而动全身，很难调整。

（4）拆分数据库

如果一直保持共用数据库的模式，则整个架构会越来越僵化，失去了微服务架构的意义。把数据库也拆分了。所有持久化层相互隔离，由各个服务自己负责。另外，为了提高系统的实时性，加入了消息队列机制。架构如下： 

<img src="F:/00-C++后台服务器学习/03-算法与设计与网络/微服务/pic/4-拆分数据库.jpg" alt="拆分数据库" style="zoom:80%;" />

完全拆分后各个服务可以采用异构的技术。比如数据分析服务可以使用数据仓库作为持久化层，以便于高效地做一些统计计算；商品服务和促销服务访问频率比较大，因此加入了缓存机制等。 

## 3 微服务优点

| 比较点    | 单体服务                                                   | 微服务                                                       |
| --------- | ---------------------------------------------------------- | ------------------------------------------------------------ |
| 业务功能  | 单体应用的时代，公共的业务功能经常没有明确的归属           | 使整个系统的分工更加明确，责任更加清晰，每个人专心负责为其他人提供更好的服务 |
| 数据库    | 数据库是共用的，数据库成为性能瓶颈，并且有单点故障的风险。 | 数据库也拆分了。所有持久化层相互隔离，由各个服务自己负责     |
| 代码重复  | 网站和移动端应用有很多相同业务逻辑的重复代码               | 各个应用后台只需从这些服务获取所需的数据，从而删去了大量冗余的代码 |
| 开发/部署 | 即使只改动一个小功能，也需要整个应用一起发布               | 只需发布自己维护的服务                                       |

## 4 带来的问题

（1）以往单体应用，排查问题通常是看一下日志，研究错误信息和调用堆栈 

（2） 而**微服务架构整个应用分散成多个服务，定位故障点非常困难** ，小明一个台机器一台机器地查看日志，一个服务一个服务地手工调用。经过十几分钟的查找，小明终于定位到故障点：促销服务由于接收的请求量太大而停止响应了。其他服务都直接或间接地会调用促销服务，于是也跟着宕机了。

**在微服务架构中，一个服务故障可能会产生雪崩效用，导致整个系统故障**。其实在节前，小明和小红是有做过**请求量评估**的。按照预计，服务器资源是足以支持节日的请求量的，所以肯定是哪里出了问题。不过形势紧急，随着每一分每一秒流逝的都是白花花的银子，因此小明也没时间排查问题，当机立断在云上新建了几台虚拟机，然后一台一台地部署新的促销服务节点。几分钟的操作后，系统总算是勉强恢复正常了。整个故障时间内估计损失了几十万的销售额，三人的心在滴血……



1. 单体应用问题排查思路 = 查看日志，研究错误信息 + debug 打印堆栈 + wireshark工具 + 消息队列是否阻塞

2. 微服务排查 = 一个台机器一台机器地查看日志，一个服务一个服务地手工调用
3. 雪崩效应：**在微服务架构中，一个服务故障可能会产生雪崩效用，导致整个系统故障**
4. 请求量评估
5. 云上新建了几台虚拟机，然后一台一台地部署新的促销服务节点

6. 日志分析工具

事后，小明简单写了个**日志分析工具**（量太大了，文本编辑器几乎打不开，打开了肉眼也看不过来），统计了促销服务的访问日志，发现在故障期间，商品服务由于代码问题，在某些场景下会对促销服务发起大量请求。这个问题并不复杂，小明手指抖一抖，修复了这个价值几十万的Bug。

问题是解决了，但谁也无法保证不会再发生类似的其他问题。微服务架构虽然逻辑设计上看是完美的，但就像积木搭建的华丽宫殿一样，经不起风吹草动。微服务架构虽然解决了旧问题，也引入了新的问题：

```
1-微服务架构整个应用分散成多个服务，定位故障点非常困难。
2-稳定性下降。服务数量变多导致其中一个服务出现故障的概率增大，并且一个服务故障可能导致整个系统挂掉。事实上，在大访问量的生产场景下，故障总是会出现的。
3-服务数量非常多，部署、管理的工作量很大。
4-开发方面：如何保证各个服务在持续开发的情况下仍然保持协同合作。
5-测试方面：服务拆分后，几乎所有功能都会涉及多个服务。原本单个程序的测试变为服务间调用的测试。测试变得更加复杂。
```



## 5 解决问题

 对故障的处理一般从两方面入手，一方面尽量减少故障发生的概率，另一方面降低故障造成的影响。 

![解决问题](pic\5-解决问题.jpg)

### 5.1 监控 - 发现故障的征兆

在高并发分布式的场景下，故障经常是突然间就雪崩式爆发。所以必须建立完善的监控体系，尽可能发现故障的征兆。

**微服务架构中组件繁多**，各个组件所需要监控的指标不同。比如Redis缓存一般监控占用磁盘空间，业务服务监控并发数、响应延迟、错误率等。因此如果做一个大而全的监控系统来监控各个组件是不大现实的，而且扩展性会很差。一般的做法是让各个组件提供报告自己当前状态的接口（metrics接口），这个接口输出的数据格式应该是一致的。

然后部署一个指标采集器组件，定时从这些接口获取并保持组件状态，同时提供查询服务。

最后还需要一个UI，从指标采集器查询各项指标，绘制监控界面或者根据阈值发出告警。



大部分组件都不需要自己动手开发，网络上有开源组件。小明下载了**RedisExporter和MySQLExporter，这两个组件分别提供了Redis缓存和MySQL数据库的指标接口**。微服务则根据各个服务的业务逻辑实现自定义的指标接口。然后小明**采用Prometheus作为指标采集器**，**Grafana配置监控界面和邮件告警**。这样一套微服务监控系统就搭建起来了：

![微服务监控系统](pic\5-微服务监控系统.jpg)

### 5.2 定位问题 - 链路跟踪

（1）链路跟踪的是什么？及其作用

在微服务架构下，一个用户的请求往往涉及多个内部服务调用。为了方便定位问题，需要能够记录每个用户请求时，微服务内部产生了多少服务调用，及其调用关系。这个叫做链路跟踪。 

![链路跟踪](pic\7-链路追踪.jpg)



（2）链路跟踪的实现

要实现链路跟踪，每次服务调用会在HTTP的HEADERS中记录至少记录四项数据： 

```
traceId：traceId标识一个用户请求的调用链路。具有相同traceId的调用属于同一条链路。
spanId：标识一次服务调用的ID，即链路跟踪的节点ID。
parentId：父节点的spanId。
requestTime & responseTime：请求时间和响应时间。
```

![链路跟踪](pic\6-链路追踪.jpg)

（3）链路跟踪UI展示

另外，还需要调用日志收集与存储的组件，以及展示链路调用的UI组件。 

![日志收集及存储](pic\8-日志收集及存储.jpg)

以上只是一个极简的说明，关于链路跟踪的理论依据可详见Google的[Dapper](https://link.zhihu.com/?target=http%3A//bigbully.github.io/Dapper-translation/)

了解了理论基础后，小明选用了**Dapper的一个开源实现Zipkin**。然后手指一抖，写了个HTTP请求的拦截器，在每次HTTP请求时生成这些数据注入到HEADERS，同时异步发送调用日志到Zipkin的日志收集器中。这里额外提一下，HTTP请求的拦截器，可以在微服务的代码中实现，也可以使用一个网络代理组件来实现（不过这样子每个微服务都需要加一层代理）。

链路跟踪只能定位到哪个服务出现问题，不能提供具体的错误信息。查找具体的错误信息的能力则需要由日志分析组件来提供。

### 5.3 分析问题-日志分析

（1）为啥需要日志分析

日志分析组件应该在微服务兴起之前就被广泛使用了。即使单体应用架构，当访问数变大、或服务器规模增多时，日志文件的大小会膨胀到难以用文本编辑器进行访问，更糟的是它们分散在多台服务器上面。排查一个问题，需要登录到各台服务器去获取日志文件，一个一个地查找（而且打开、查找都很慢）想要的日志信息。

因此，在应用规模变大时，我们需要一个日志的“**搜索引擎**”。以便于能准确的找到想要的日志。另外，数据源一侧还需要收集日志的组件和展示结果的UI组件：

![日志分析](pic\9-日志分析.jpg)

（2）日志分析实现

小明调查了一下，使用了大名鼎鼎地ELK日志分析组件。ELK是Elasticsearch、Logstash和Kibana三个组件的缩写。

- Elasticsearch：搜索引擎，同时也是日志的存储。
- Logstash：日志采集器，它接收日志输入，对日志进行一些预处理，然后输出到Elasticsearch。
- Kibana：UI组件，通过Elasticsearch的API查找数据并展示给用户。

最后还有一个小问题是如何将日志发送到Logstash。一种方案是在日志输出的时候直接调用Logstash接口将日志发送过去。这样一来又（咦，为啥要用“又”）要修改代码……于是小明选用了另一种方案：日志仍然输出到文件，每个服务里再部署个Agent扫描日志文件然后输出给Logstash。

### 5.4 网关-权限控制，服务治理

拆分成微服务后，出现大量的服务，大量的接口，使得整个调用关系乱糟糟的。经常在开发过程中，写着写着，忽然想不起某个数据应该调用哪个服务。或者写歪了，调用了不该调用的服务，本来一个只读的功能结果修改了数据……

为了应对这些情况，微服务的调用需要一个把关的东西，也就是网关。在调用者和被调用者中间加一层网关，每次调用时进行权限校验。另外，网关也可以作为一个提供服务接口文档的平台。

使用网关有一个问题就是要决定在多大粒度上使用：最粗粒度的方案是整个微服务一个网关，微服务外部通过网关访问微服务，微服务内部则直接调用；最细粒度则是所有调用，不管是微服务内部调用或者来自外部的调用，都必须通过网关。折中的方案是按照业务领域将微服务分成几个区，区内直接调用，区间通过网关调用。

由于整个网上超市的服务数量还不算特别多，小明采用的最粗粒度的方案：

![权限控制，服务治理](pic\10-网关权限控制.jpg)

### 5.5 服务注册与发现-动态扩容



### 5.6 熔断、服务降级、限流





