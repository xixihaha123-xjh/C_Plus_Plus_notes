# 0 时间空间复杂度

## 0.1 空间复杂度与时间复杂度互换

1. 当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用时间换空间的设计思路。  

2. 缓存实际上就是利用了空间换时间的设计思想。如果我们把数据存储在硬盘上，会比较节省内存，但每次查找数据都要询问一次硬盘，会比较慢。但如果我们通过缓存技术，事先将数据加载在内存中，虽然会比较耗费内存空间，但是每次数据查询的速度就大大提高了。  
3. 对于执行较慢的程序，可以通过消耗更多的内存（空间换时间）来进行优化；而消耗过多内存的程序，可以通过消耗更多的时间（时间换空间）来降低内存的消耗。你还能想到其他时间换空间或者空间换时间的例子吗？  

## 0.2 栈的时间空间复杂度

1. 不管是顺序栈还是链式栈，我们存储数据只需要一个大小为n的数组就够了。在入栈和出栈过程中，只需要一两个临时变量存储空间，所以空间复杂度是O(1)。
   注意，这里存储数据需要一个大小为n的数组，并不是说空间复杂度就是O(n)。因为，这n个空间是必须的，无法省掉。所以我们说空间复杂度的时候，是指除了原本的数据存储空间外，算法运行还需要额外的存储空间。
2.  支持动态扩容的顺序栈，你需要重点掌握它的均摊时间复杂度分析方法。  摊还分析法



# 1 数组

## 1.1 数组访问越界

1. C语言中，只要不是访问受限的内存，所有的内存空间都是可以自由访问的。

2. 根据我们前面讲的数组寻址公式， a[3]也会被定位到某块不属于数组的内存地址上，而这个地址正好是存储变量i的内存地址，那么a[3]=0就相当于i=0，所以就会导致代码无限循环。  

3.   函数体内的局部变量存在栈上，且是连续压栈。在Linux进程的内存布局中，栈区在高地址空间，从高向低增长。变量i和arr在相邻地址，且i比arr的地址大，所以arr越界正好访问到i。当然，前提是i和arr元素同类型，否则那段代码仍是未决行为
4.   例子中死循环的问题跟编译器分配内存和字节对齐有关 数组3个元素 加上一个变量a 。 4个整数刚好能满足8字节对齐 所以i的地址恰好跟着a2后面 导致死循环，如果数组本身有4个元素 则这里不会出现死循环。。因为编译器64位操作系统下 默认会进行8字节对齐 变量i的地址就不紧跟着数组后面了  


```c
int main(int argc, char* argv[])
{
	int i = 0;
	int arr[3] = {0};
	for(; i<=3; i++)
    {
		arr[i] = 0;
		printf("hello world\n");
	}
	return 0;
}
```

## 1.2   JVM的标记清除垃圾回收算法  



## 1.3 二维数组内存寻址公式

### 1.3.1 一维数组

1. a[k]就表示偏移k个type_size的位置，所以计算a[k]的内存地址只需要用这个公式：
   `a[k]_address = base_address + k * type_size `

2. 如果数组从1开始计数，那我们计算数组元素a[k]的内存地址就会变为：
   `a[k]_address = base_address + (k-1)*type_size  `

### 1.3.2 二维数组

```
a[i][j]   # i行 j列
a[m][n]_address = base_address + n * type_size + j * m * type_size 
                = (n + j * m) * size_type
```

# 2 链表

## 2.1 约瑟夫环





## 2.2 LRU缓存淘汰算法

### 2.2.1 单链表实现

1. 我的思路是这样的：
   我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。
2. 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。
3. 如果此数据没有在缓存链表中，又可以分为两种情况：
   如果此时缓存未满，则将此结点直接插入到链表的头部；
   如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。

### 2.2.2 数组实现

1. 如何利用数组实现LRU缓存淘汰策略呢？我把这个问题留给你思考。

   

2. CPU在从内存读取数据的时候，会先把读取到的数据加载到CPU的缓存中。而CPU每次从内存读取数据并不是只读取那个特定要访问的地址，而是读取一个数据块(这个大小我不太确定 )并保存到CPU缓存中，然后下次访问内存数据的时候就会先从CPU缓存开始查找，如果找到就不需要再从内存中取。这样就实现了比内存访问速度更快的机制，也就是CPU缓存存在的意义：为了弥补内存访问速度过慢与CPU执行速度快之间的差异而引入。对于数组来说，存储空间是连续的，所以在加载某个下标的时候可以把以后的几个下标元素也加载到CPU缓存这样执行速度会快于存储空间不连续的链表存储。



## 2.3 思考题

1. 如何判断一个字符串是否是回文字符串的问题，我想你应该听过，我们今天的思题题就是基于这个问题的改造版本。如果字符串是通过单链表来存储的，那该如何来判断是一个回文串呢？你有什么好的解决思路呢？相应的时间空间复杂度又是多少呢?



2. “回文串”是一个正读和反读都一样的字符串，比如“level”或者“noon”等等就是回文串

3. 解决办法：快慢指针法



## 2.4 链表操作

### 2.4.1 反转



### 2.4.2 有序链表合并



# 3 栈

## 3.1 栈应用

### 3.1.1 栈在函数调用中的应用

1. 操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构，用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。

### 3.1.2 栈实现浏览器前进后退功能

1. 我们使用两个栈， X和Y，我们把首次浏览的页面依次压入栈X 
2. 后退：从栈X中出栈，并将出栈的数据依次放入栈Y
3. 前进：前进按钮时，我们依次从栈Y中取出数据，放入栈X中
4. X 中没有数据时，那就说明没有页面可以继续后退浏览了  

5. 栈Y中没有数据，那就说明没有页面可以点击前进按钮浏览了
6. 浏览新页面：栈Y中的页面无法在通过前进或后退按钮重复查看了，清空栈Y

## 3.2 思考

### 3.2.1 函数调用为什么要使用栈?

1. 为什么函数调用要用“栈”来保存临时变量呢？用其他数据结构不行吗？
2. 其实，我们不一定非要用栈来保存临时变量，只不过如果这个函数调用符合后进先出的特性，用栈这种数据结构来实现，是最顺理成章的选择。
3. 从调用函数进入被调用函数，对于数据来说，变化的是什么呢？是作用域。所以根本上，只要能保证每进入一个新的函数，都是一个新的作用域就可以。而要实现这个，用栈就非常方便。在进入被调用函数的时候，分配一段栈空间给这个函数的变量，在函数结束的时候，将栈顶复位，正好回到调用函数的作用域内。  

### 3.2.2 数据结构栈与内存中的栈

1. 内存中的堆栈和数据结构堆栈不是一个概念，可以说内存中的堆栈是真实存在的物理区，数据结构中的堆栈是抽象的数据存储结构。  

## 3.3 栈的实现

### 3.3.1 链式栈





# 4 队列

## 4.1 问题

1.   CPU资源是有限的，任务的处理速度与线程个数并不是线性正相关。相反，过多的线程反而会导致CPU频繁切换，处理性能下降。所以，线程池的大小一般都是综合考虑要处理任务的特点和硬件环境，来事先设置的。
2.   当我们向固定大小的线程池中请求一个线程时，如果线程池中没有空闲资源了，这个时候线程池如何处理这个请求？是拒绝请求还是排队请求？各种处理策略又是怎么实现的呢？  



 这种实现思路中，出队操作的时间复杂度仍然是O(1)，但入队操作的时间复杂度还是O(1)吗？你可以用我们第3节、第4节讲的算法复杂度分析方法，自己试着分析一下  



# 5 排序

## 5.1 冒泡排序

插入排序和冒泡排序的时间复杂度相同，都是O(n2)，在实际的软件开发里，为什么我们更倾向于使用插入排序算法而不是冒泡排序算法呢？

